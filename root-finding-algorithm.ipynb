{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root-finding algorithms share a very straightforward and intuitive approach to approximating roots. The general structure goes something like: a) start with an initial guess, b) calculate the result of the guess, c) update the guess based on the result and some further conditions, d) repeat until you’re satisfied with the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Method/Line Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple question: $f(x)=x^2-20$\n",
    "\n",
    "naive_root begin with something like 4.5 (you have the luxury of knowing what a good first guess is – this is not always the case), square it to get 20.25, reduce 4.5 by some small amount since the result is greater than 20, recalculate, etc. until you get an answer you’re satisfied with. Our naive root-finding algorithm looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1 µs ± 100 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "root is: 4.472135970023498\n",
      "steps taken: 4\n"
     ]
    }
   ],
   "source": [
    "def naive_root(f, x0, tol, step): \n",
    "    steps_taken = 0\n",
    "    while abs(f(x0)) > tol:\n",
    "        if f(x0) > 0:\n",
    "            x0 -= step\n",
    "        elif f(x0) < 0:\n",
    "            x0 += step\n",
    "        else:\n",
    "            return x0\n",
    "        steps_taken += 1 \n",
    "    return x0, steps_taken\n",
    " \n",
    "f = lambda x: x**2 - 20\n",
    "%timeit root, steps = naive_root(f, x0=4.5, tol=.01, step=.001)\n",
    "print(\"root is:\", root)\n",
    "print(\"steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bisection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bisection method introduces a simple idea to hone in on the root. Start with two guesses such that f(guess_1) and f(guess_2) are of opposite sign. This means that we have one guess that’s too large and another guess that’s too small. The idea is to gradually squeeze the guess that’s too high and the guess that’s too low towards zero until we’re satisfied that the range between the two is small enough or equal to zero.\n",
    "\n",
    "At each step we take the midpoint of the two guesses. If the midpoint is zero (the guesses are the same) or if the guesses are sufficiently close to one another, we return the midpoint. Otherwise, if the f(midpoint) is negative, then we replace the lower bound with the midpoint, and if f(midpoint) is positive, then we replace the upper bound with the midpoint. And, of course, repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.39 µs ± 157 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "root is: 4.472135970023498\n",
      "steps taken: 4\n"
     ]
    }
   ],
   "source": [
    "def bisection(f, lower, upper, max_iters=50, tol=1e-5): \n",
    "    steps_taken = 0\n",
    "    while steps_taken < max_iters:\n",
    "        m = (lower + upper) / 2.0\n",
    "        if m == 0 or abs(upper-lower) < tol:\n",
    "            return m, steps_taken\n",
    "        if f(m) > 0:\n",
    "            upper = m\n",
    "        else:\n",
    "            lower = m\n",
    " \n",
    "        steps_taken += 1 \n",
    "    final_estimate = (lower + upper) / 2.0\n",
    "    return final_estimate, steps_taken \n",
    "\n",
    "f = lambda x: x**2 - 20\n",
    "%timeit root, steps = bisection(f, 1, 8)\n",
    "print(\"root is:\", root)\n",
    "print(\"steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton-Raphson Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve probably guessed that the derivative is an obvious candidate for improving step sizes: the derivative tells us about the direction and step size to take on reasonably convex, continuous, well-behaved functions; all we need to do is find a point on the curve where the derivative is zero.\n",
    "\n",
    "For Newton-Raphson, we supply an initial guess, calculate the derivative of f at the initial guess, calculate where the derivative intersects the x-axis, and use that as our next guess. \n",
    "\n",
    "We have $f'(x_{n})*(x_{n+1}-x_{n})=0-f(x_n)$, that is $\\delta x=-f(x_n)/f'(x_n)$\n",
    "\n",
    "For this code we approximate the derivative of univariate f at x so that you can play around with the function without having to calculate the derivatives, but you can easily substitute in the actual derivative function to get similar results. The method can be extended to n dimensions with the Jacobian and/or higher orders of the Taylor series expansion, but for now we’ll keep it simple.\n",
    "\n",
    "We know that Deep Learning Tools(such as PyTorch) can calculate derivations automatically and fast, thus it is probably a good idea to implement this algorithm on PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.06 µs ± 18.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "root is: 4.472135970023498\n",
      "steps taken: 4\n"
     ]
    }
   ],
   "source": [
    "def discrete_method_approx(f, x, h=.00000001):\n",
    "    return (f(x+h) - f(x)) / h\n",
    " \n",
    "def newton_raphson(f, x, tol=.001):\n",
    "    steps_taken = 0\n",
    " \n",
    "    while abs(f(x)) > tol:\n",
    "        df = discrete_method_approx(f, x)\n",
    "        x = x - f(x)/df\n",
    "        steps_taken += 1\n",
    "    return x, steps_taken\n",
    " \n",
    "f = lambda x: x**2 - 20\n",
    "%timeit root, steps = newton_raphson(f, 8)\n",
    "print(\"root is:\", root)\n",
    "print(\"steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this method takes far fewer iterations than the Bisection Method, and returns an estimate far more accurate than our imposed tolerance (Python gives the square root of 20 as 4.47213595499958)\n",
    "\n",
    "The drawback with Newton’s Method is that we need to compute the derivative at each iteration. While it wasn’t a big deal for our toy problem, computing gradients and higher order derivatives for large, complex systems of equations can be very expensive. So while Newton’s Method may find a root in fewer iterations than Algorithm B, if each of those iterations takes ten times as long as iterations in Algorithm B then we have a problem. To remedy this, let’s look at some Quasi-Newtonian methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi-Newtonian: Secant Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the Quasi-Newtonian Secant Method and other Quasi-Newtonian methods is to substitute the expensive calculation of the derivative/Jacobian/Hessian at each step with an inexpensive but good-enough approximation. All of the more popular methods (BFGS, Secant, Broyden, etc.) have the same basic form, save for different rules about how best to approximate the gradient and update the guess.\n",
    "\n",
    "You can think of the Secant Method as derivative-lite. Instead of computing the derivative, we approximate it using two points (x0, f(x0)) and (x1, f(x1)), calculate where the line intercepts the x-axis, and use that as one of our new points. This provides a fast way to generate a line that should approximate the tangent line to the function somewhere between these two points.\n",
    "\n",
    "Given our two initial guesses x_{0} and x_{1}, the secant line in slope-intercept form is:\n",
    "\n",
    "$y = \\frac{f(x_{n-1}) -f(x_{n-2})}{x_{n-1} - x_{n-2}} (x - x_{n-1}) + f(x_{n-1})$\n",
    "\n",
    "Setting y to 0 (our new guess is where the line intercepts the x-axis), we get:\n",
    "\n",
    "$x = x_{n-1} - f(x_{n-1}) \\frac{x_{n-1} - x_{n-2}}  {f(x_{n-1}) - f(x_{n-2})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.85 µs ± 72.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "root is: 4.472135970023498\n",
      "steps taken: 4\n"
     ]
    }
   ],
   "source": [
    "def secant_method(f, x0, x1, max_iter=100, tol = 1e-5):\n",
    "    steps_taken = 1\n",
    "    while steps_taken < max_iter and abs(x1-x0) > tol:\n",
    "        x2 = x1 - ((f(x1) * (x1 - x0)) / (f(x1) - f(x0)))\n",
    "        x1, x0 = x2, x1\n",
    "        steps_taken += 1\n",
    "    return x2, steps_taken\n",
    " \n",
    "f = lambda x: x**2 - 20\n",
    " \n",
    "%timeit root, steps = secant_method(f, 2, 8)\n",
    "print(\"root is:\", root)\n",
    "print(\"steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Quadratic Interpolation and Lagrange Polynomials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is similar to the secant method but instead is initialized with three points, interpolates a polynomial curve based on those points, calculates where the curve intercepts the x-axis and uses this point as the new guess in the next iteration.\n",
    "\n",
    "The quadratic interpolation method is the Lagrange polynomial:\n",
    "\n",
    "$L(x) = \\sum_{j=0}^{k} y_j l_j (x)$\n",
    "\n",
    "where\n",
    "\n",
    "$l_j(x) = \\prod_{0 \\leq m \\leq k , m \\neq j} \\frac{x - x_m}{x_j - x_m}$\n",
    "\n",
    "is carried out with three points to get a second degree polynomial curve. Basically, in this instance we create three basic l(x) degree two polynomial curves, where each curve is zero when m != j and approximates the f(m) value otherwise. The Lagrange polynomial is designed to do exactly this. You get three curves that each pass through one of the points to be interpolated and is zero at all other points, then take the linear combination of those curves for an interpolation that passes through all desired points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.55 µs ± 17.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "root is: 4.472135957903189\n",
      "steps taken: 2\n"
     ]
    }
   ],
   "source": [
    "def inverse_quadratic_interpolation(f, x0, x1, x2, max_iter=20, tol=1e-5):\n",
    "    steps_taken = 0\n",
    "    while steps_taken < max_iter and abs(x1-x0) > tol: # last guess and new guess are v close\n",
    "        fx0 = f(x0)\n",
    "        fx1 = f(x1)\n",
    "        fx2 = f(x2)\n",
    "        L0 = (x0 * fx1 * fx2) / ((fx0 - fx1) * (fx0 - fx2))\n",
    "        L1 = (x1 * fx0 * fx2) / ((fx1 - fx0) * (fx1 - fx2))\n",
    "        L2 = (x2 * fx1 * fx0) / ((fx2 - fx0) * (fx2 - fx1))\n",
    "        new = L0 + L1 + L2\n",
    "        x0, x1, x2 = new, x0, x1\n",
    "        steps_taken += 1\n",
    "    return x0, steps_taken\n",
    " \n",
    "f = lambda x: x**2 - 20\n",
    " \n",
    "%timeit root, steps = inverse_quadratic_interpolation(f, 4.3, 4.4, 4.5)\n",
    "print(\"root is:\", root)\n",
    "print(\"steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brent's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brent’s Method seeks to combine the robustness of the bisection method with the fast convergence of inverse quadratic interpolation. The basic idea is to switch between inverse quadratic interpolation and bisection based on the step performed in the previous iteration and based on inequalities gauging the difference between guesses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.4 µs ± 336 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "root is: 4.472135957903189\n",
      "steps taken: 2\n"
     ]
    }
   ],
   "source": [
    "def brents(f, x0, x1, max_iter=50, tol=10e-5):\n",
    " \n",
    "    fx0 = f(x0)\n",
    "    fx1 = f(x1)\n",
    " \n",
    "    assert (fx0 * fx1) <= 0, \"Root not bracketed\" \n",
    " \n",
    "    if abs(fx0) < abs(fx1):\n",
    "        x0, x1 = x1, x0\n",
    "        fx0, fx1 = fx1, fx0\n",
    " \n",
    "    x2, fx2 = x0, fx0\n",
    " \n",
    "    mflag = True\n",
    "    steps_taken = 0\n",
    " \n",
    "    while steps_taken < max_iter and abs(x1-x0) > tol:\n",
    "        fx0 = f(x0)\n",
    "        fx1 = f(x1)\n",
    "        fx2 = f(x2)\n",
    " \n",
    "        if fx0 != fx2 and fx1 != fx2:\n",
    "            L0 = (x0 * fx1 * fx2) / ((fx0 - fx1) * (fx0 - fx2))\n",
    "            L1 = (x1 * fx0 * fx2) / ((fx1 - fx0) * (fx1 - fx2))\n",
    "            L2 = (x2 * fx1 * fx0) / ((fx2 - fx0) * (fx2 - fx1))\n",
    "            new = L0 + L1 + L2\n",
    " \n",
    "        else:\n",
    "            new = x1 - ((fx1 * (x1 - x0)) / (fx1 - fx0))\n",
    " \n",
    "        if ((new < ((3 * x0 + x1) / 4) or new > x1) or\n",
    "            (mflag == True and (abs(new - x1)) >= (abs(x1 - x2) / 2)) or\n",
    "            (mflag == False and (abs(new - x1)) >= (abs(x2 - d) / 2)) or\n",
    "            (mflag == True and (abs(x1 - x2)) < tol) or\n",
    "            (mflag == False and (abs(x2 - d)) < tol)):\n",
    "            new = (x0 + x1) / 2\n",
    "            mflag = True \n",
    "        else:\n",
    "            mflag = False\n",
    " \n",
    "        fnew = f(new)\n",
    "        d, x2 = x2, x1\n",
    " \n",
    "        if (fx0 * fnew) < 0:\n",
    "            x1 = new\n",
    "        else:\n",
    "            x0 = new\n",
    " \n",
    "        if abs(fx0) < abs(fx1):\n",
    "            x0, x1 = x1, x0 \n",
    "        steps_taken += 1\n",
    " \n",
    "    return x1, steps_taken\n",
    " \n",
    "f = lambda x: x**2 - 20\n",
    " \n",
    "%timeit root, steps = brents(f, 2, 5, tol=10e-5)\n",
    "print(\"root is:\", root)\n",
    "print(\"steps taken:\", steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
